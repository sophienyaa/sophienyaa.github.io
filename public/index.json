[{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["hacking","hardware","catprinter","uwu","nyaa","cat printer","printer","ipp"],"content":" Allow me to introduce you to this\u0026hellip;\nThis amazing piece of technology is a cat printer. It is a small, battery powered, monochrome thermal printer that is able to be controlled over Bluetooth Low Energy.\nIt\u0026rsquo;s designed to portable for use with your smartphone. With it, you can print your photos on the go, just like a polaroid! (but way worse)\nHere is an example:\nOriginal Image Cat Printer Hold up, what? why? Who wouldn\u0026rsquo;t want to print their photos in glorious 1 bit dithered monochrome?!\nOne of my favourite youtubers had covered similar ones, and I then saw one of my friends tweet about it. How could I say no to such a glorious device?\nObjectively crappy output aside, the prints do have a certain aesthetic to them that I like.\nBut, truth be told, I bought the cat printer mostly because it seemed like a fun thing to play with. But, as it turns out, it was quite hackable.\n\u0026hellip;also its cute.\nOook, go on then\u0026hellip; These little printers are available on the usual online retailers, like Amazon and AliExpress for ~¬£30. There are also other, non animal based versions too.\nThey are intended to be used with a mobile application called \u0026ldquo;iPrint\u0026rdquo; in order to print text or images.\nBut, what if you want to use your cat printer in another way? With your computer or some other device? Well, thanks to other hackers there are plenty of options out there;\nThere is a hackaday article here that covers both Arduino and macOS options by Larry Bank.\nIf CircutPython is more your jam, you can check out this tutorial on Adafruit here by Jeff Epler.\nOr, if you\u0026rsquo;re more into regular python, or rust there is a good list of projects here.\nBut, like any hacker knows, the fact there is already a way to do something isn\u0026rsquo;t a good enough reason not to do it yourself! So that is what I did!\nBut first, let\u0026rsquo;s talk a little about the\u0026hellip;\nHardware The hardware is pretty well documented already, a good example is the writeup by WerWolv.\nBut, to give some context here is a quick overview;\nIt\u0026rsquo;s a thermal printer and uses 57mm paper, similar to what you\u0026rsquo;d find in card machines and the like. It can fit approx 40mm diameter rolls of paper.\nThe print resolution is 384px wide (203dpi), being a thermal printer, it can only print in monochrome (1bit / black and white)\nThe brains of the operation is a JL MCU that there is vanishingly little documentation for, and the printer communicates with other devices via Bluetooth Low Energy (BLE).\nIt\u0026rsquo;s powered by an internal lithium battery and is charged via micro-usb.\nAnd the most important feature, it has little ears and a cute face.\nSo with that in mind, on to the\u0026hellip;\nSoftware I decided to build my version of cat printer goodness in NodeJS, which I\u0026rsquo;ve called printkitty.js, imaginative, I know. You can check it out on GitHub here\nI chose NodeJS mostly because it\u0026rsquo;s what I am comfortable with. This, as it turns out, may not have been the best decision\u0026hellip; due to reasons I\u0026rsquo;ll get in to later.\nThe printer has no \u0026lsquo;pure\u0026rsquo; text mode or inbuilt fonts. It simply prints everything as an image. So with that in mind, my initial goal was simply to be able to send images to the printer.\nBluetooth Low Energy To do this, the first thing I needed was a BLE library. I settled on noble, as it seemed easy enough to work with, and there aren\u0026rsquo;t a lot of other choices for Node.\nI then came across this repository from JJJollyjim that collects a bunch of cat printer projects, and then a document by bad_opcode that had nice and clear documentation of the protocol used.\nOnce I was able to connect to the printer with noble, I scanned for characteristics and found quite a few\u0026hellip; AE01,AE02,AE03,AE04,AE05,AE10. with AE01 being write only, and AE10 being read/write, and AE02 and AE04 being for notifications.\nI initially tried the AE10 read/write characteristic, but had no luck making the printer do anything. I then tried AE01 and wrote the bytes for a \u0026rsquo;eject paper\u0026rsquo;, and much to my excitement, paper came out of the printer.\nI then tried to get info, while listening to AE02 and I did indeed receive some data on that characteristic. With the knowledge that this was likely to work\u0026hellip;\nLet\u0026rsquo;s try and make it print something I had read that the printer essentially took an array of bits to construct an image, 1 for black (e.g activate the printhead) and 0 for white. (e.g dont)\nThis is where my choice of NodeJS started to become less than ideal. JavaScript is not exactly the most low level language, and working with individual bits isn\u0026rsquo;t particularly ergonomic, compared to say C/C++ (which I am somewhat used to in playing with microcontrollers).\nWith that said, I was able to construct bit strings (e.g \u0026quot;11111111\u0026quot;) and parse those in to integers (e.g 255 / 0xFF). That has proven to be good enough. So I \u0026lsquo;drew\u0026rsquo; a square in bits, parsed it to bytes and constructed an array of with one Buffer for each like, and each buffer.\nI sent the square to the printer, and it printed, but didn\u0026rsquo;t advance as it did so. So I threw a call to feed the paper by one step each iteration. I then had a square, but the sides of it were on the inside, so It looked more like an I. I then went back and re-read the document and realised I missed this very important bit under the print section\u0026hellip; \u0026ldquo;with each byte packed with the least significant bit first.\u0026rdquo;\nThe easiest / laziest way to resolve this was simply to reverse the bit strings and then parse that into bytes. There is probably a better way to do this, bit it works well enough for now.\nAfter doing that, I got my square! Now on to the next challenge, trying to print something meaningful (\u0026hellip;and by that, I mean a picture of grumpy cat).\nParsing images in NodeJS Turns out this was another sucky thing about using NodeJS, there aren\u0026rsquo;t a huge amount of image processing libraries. I settled on sharp and while it is very performant and easy to use, there aren\u0026rsquo;t a lot of options for producing pure monochrome images. I tried using its inbuilt dithering but always ended up with an image that was grey and white, not black and white.\nI then came across noopkat\u0026rsquo;s floyd-steinberg package, that was able to produce the results I was after.\nAfter pluming it and sharp together, I was able to produce dithered, monochrome images from a wide range of input image formats. There is definitely better ways to do this, so any suggestions are welcome!\nBuilding a bitmap Now that I had monochrome images, I needed to turn those into 1bpp bitmaps that the printer could understand. If you\u0026rsquo;ve ever worked with small monochrome displays and microcontrollers this should be sort familiar.\nAs said above, the format is 1 bit per pixel, with 0 for white and 1 for black, grouped in to bytes with the least significant bit first. As the print area is 348px wide, this means 48 bytes of data per line.\nI learnt here, that if you provide less than 48 bytes per line, the printer will not automatically advance when given the next line.\nThe final data structure for my bitmap was an array of Buffer objects, with each one being 48 bytes. When initialised they are filled with 0\u0026rsquo;s so if the image is less than 348px wide, it will be padded with 0\u0026rsquo;s.\nNow that I had all this, I was able to start..\nPrinting actual images I started trying to feed data to the printer, following the same set of commands that existing code did;\nSet the quality, I\u0026rsquo;ve set it to \u0026lsquo;3\u0026rsquo; and this seems to work fine Send the first magic \u0026rsquo;lattice\u0026rsquo; command Set the print \u0026rsquo;energy\u0026rsquo; to medium Set the drawing mode (it has a \u0026rsquo;text\u0026rsquo; mode, to spite not having a way to print text) Setting the feed speed to 0x23, as seems to be done in the other solutions Sending the print data Feeding the paper for 120 steps Doing the last \u0026rsquo;lattice\u0026rsquo; command This order of operations was discovered by during the reverse engineering of the \u0026ldquo;iPrint\u0026rdquo; app done by WerWolv.\nHowever, each time I tried, I\u0026rsquo;d only get a few lines of the print out before it would stop. This is because I had neglected to put a delay between each line of the print data.\nAs others had discovered and documented, if you don\u0026rsquo;t do this, the printer will get overwhelmed and stop printing.\nHerein lies yet another issue with JavaScript. There is no native delay() or sleep() functionality. Annoying as it is, it does makes sense when you understand the JS event loop.\nHowever, for this purpose it is not difficult hack one in and allow the code to pause for 10ms between sending commands to the printer. This solved the the issue and I was finally able to print images successfully!\nNow simply by running printkitty --image grumpy.png I was able to get this:\nPrinting images is cool and all, but\u0026hellip;\nWhat about text? Because our little cat printer can only do images, if we want to print text we need to find a way to turn our text into an image!\nThis was where using sharp turned out to be a good decision. It is incredibly easy to build an SVG (as after all SVGs are markup very similar to HTML) that contains the text you want to print, and then turn that in to an image and print it in the same way as you do any other.\nI found a very cool article from DigitalOcean about how to use sharp for more general image processing, but it was here I found the idea of simply constructing a SVG, turning it in to an image and processing it.\nOne thing to note here, is I skip the dithering process as the generated text is always going to be monochrome. The other fun part about doing it this way, is it makes it very easy to pass in font and font size choices for our printed text.\nThis code I\u0026rsquo;ve written to handle text is pretty rudimentary, and I\u0026rsquo;ve not yet added a way to scale the height of the image with the text, but I can fix that in later releases.\nAll of this culminated in being able to run printkitty --text \u0026quot;~nyaa\u0026quot; --font \u0026quot;Comic Sans MS\u0026quot; --size 100 and getting this:\nSo I can print images, and even text now, but to do so I need to run them through my app. What if I wanted to be able to just print from any application like you can with any other boring, non-cat printer?\nEnter, IPP (Internet Printing Protocol) IPP is a standard that has been around for some time, with the idea being that you can print documents over a network (or, like, the internet) to any printer without pesky things like drivers or software.\nMy boring, non-cat Samsung laser printer supports it, as do basically any modern network enabled printer. What I didn\u0026rsquo;t realise is how simple a protocol it is\nI found this package from watson that implemented a basic IPP server in node and watched his accompanying talk on the protocol and how he did it. It also supports niceties like Bonjour/zeroconf making actually adding your cat printer to your system a snap.\nThe package listens for print jobs and then outputs them to your local filesystem as postscript files. This was great, but sadly sharp doesn\u0026rsquo;t support these.\nI was again let down by NodeJS when I couldn\u0026rsquo;t find any native libraries to handle converting postscript to an image (e.g PNG) that I could easily process.\nI did however find wrappers around ghostscript, which can perform this task. But this would mean a dependancy on gs being installed. I wanted to avoid this, but sadly I could not find any other viable options.\nUltimately, I decided to skip using a wrapper and simply call gs from within my code by using Node\u0026rsquo;s child_process package. This is a bit hack-y but it works well enough for this application.\nSo with all that in place, I was able to generate a PNG image, from the received postscript print data and pass that into my existing code.\nAll of this means, I could simply run printkitty --ipp and I was able to use my cat printer from any application!\nThere is still more to do, like generally improve the code and try and hack in AirPrint support, but that will have to wait for a future post.\nOk, so what was the point of all this?\nConclusion and thanks Well\u0026hellip; the point of this\u0026hellip; was\u0026hellip; just to do it.\nTo elaborate on that, it was to learn more about my little cat-faced, thermal printing, friend by experimenting on it.\nIn these experiments, along with learning about the hardware itself, I learnt more about Node and JavaScript in general. I also learnt a little about how IPP worked, something I\u0026rsquo;d used plenty but never really thought about. I also got a handful of likes and hopefully also made some smile on twitter.\nThe friend who inspired me to get one in the first place conducted her own set of cat printer experimentation, going even further by setting up things like a telegram bot and printing images from SSTV, which are worth checking out.\nIf you\u0026rsquo;ve got your own cat printer, or been inspired to get one by this post, please give printkitty.js a try, I\u0026rsquo;d love to hear your feedback\u0026hellip; and if you go on to experiment yourself I\u0026rsquo;d absolutely love to see your car printer projects!\nFinally, I\u0026rsquo;d like to say thanks to everyone who\u0026rsquo;s work I\u0026rsquo;ve referenced in this post, as what they\u0026rsquo;ve done has enabled my experimentation here.\n","date":"2022-04-23T11:30:00+01:00","site":"https://sophieis.lgbt/","tags":["hacking","hardware","catprinter","uwu","nyaa","cat printer","printer","ipp"],"title":"Hacking cat printers for fun and... likes on twitter?","uri":"https://sophieis.lgbt/posts/2022-04-23-hacking-cat-printers-for-fun-and-likes-on-twitter/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["cyberpunk","cyberdeck","raspberry pi","sbc","hacking","hardware"],"content":" If you are a regular reader of blogs like hackaday, then you will have noticed in recent years that \u0026lsquo;cyberdecks\u0026rsquo; have become quite popular.\nMost of these are essentially custom designed/built laptops based around various SBCs, with the Rapsberry Pi being a popular choice. Some of them use Intel NUCs or other PC hardware, some even feature head mounted displays!\nThey generally have a retro-futuristic, hand-built, utilitarian aesthetic. Cyberdecks often feature in cyberpunk books, movies, video games, etc.\nFirst Attempts I love the design of these, and over the last year or so I have experimented with the idea of building my own. I have even done a few prototypes or builds that I never finished or discarded for some reason. They were all based largely around the same hardware.\nMy first go was a laser-cut acrylic design, this was before I purchased a 3D printer. I used the laser cutter at my local hackspace.\nIt was a thing, it worked but I didn\u0026rsquo;t like the design or assembly.\nIt was based around a Raspberry Pi 4, 7\u0026quot; LCD touchscreen and a \u0026lsquo;AK33\u0026rsquo; mechanical keyboard.\nI abandoned this design pretty early on, it was a pain to put together and I wasn\u0026rsquo;t happy with how it looked.\nA while later, I bought a 3d printer (Ender 3 Pro) and set about designing my next attempt.\nThis one was much better, but I still wasn\u0026rsquo;t happy.\nThis one used the same hardware, and I was sort-of happy with it, but I could never get the keyboard to sit right and it was a pain to print, so I gave up on this design.\nCurrent \u0026lsquo;Attempt\u0026rsquo; Here it is, in all its glory!\nOver the Christmas break, inspired by 100+ hours of Cyberpunk 2077 (Which, I loved, to spite its flaws) I thought I\u0026rsquo;d have another go at this whole cyberdeck thing.\nMy 3D modeling skills are slightly better than when I made the first attempt (though still very poor) so I hoped I\u0026rsquo;d have more success.\nI wanted my cyberdeck to have certain features/qualities;\nIt had to be portable, and able to run from a battery. I wanted to include an SDR in it, so it could be used as a portable listening station I wanted to use the same AK33 keyboard I had from the previous attempts I wanted it to be \u0026lsquo;clean\u0026rsquo;\u0026hellip; e.g no cables hanging out, etc. I wanted it to be easy to put together. With those goals in mind, I fired up Fusion360, a piece of software with which I have a love hate relationship and set to work.\nDesign I went with largely the same aesthetic as the first 3D printed attempt. Sort of inspired by the Amiga 600 or Commodore 64C and other similar machines, but with a screen on top.\nIf you squint hard, it almost looks like one! (Image from Wikipedia)\nWith the design somewhat laid out in my head, I started drawing. I split the machine in to 4 main sections, so as to fit on my printers bed.\n3D Models of the major components\nThe two rear sections contain most of the hardware, and are bolted together. On top go two slotted \u0026rsquo;lids\u0026rsquo; with the uprights for the display hinges.\nThe two front sections attach with tabs that slide in to the rear sections. They are also bolted in the middle.\nThe front sections only contain standoffs for they keyboard, but could easily hold additional hardware (there\u0026rsquo;s a bit of room underneath, especially towards the back.\nYou will notice the evenly-spaced holes in the bottom of the device. My idea was here that it would make it easy to add and remove hardware. Each device, like the Pi, USB Hub, etc is on a separate carrier that is bolted to the bottom of the board.\nIf you want to build your own, but are using slightly different hardware to me, all you need to do is design carriers for it, rather than changing the whole case.\nQuicker than re-printing the whole section!\nIt also made it much easier, as if I made a mistake on the hole spacing for the RPi, I only needed to re-print the carrier, not the whole device!\nWith all that in mind, let\u0026rsquo;s turn to the actual hardware in the cyberdeck.\nHardware I am using largely the same hardware from my first attempts, but let\u0026rsquo;s look at it in a little more detail.\nThe SBC is a Raspberry Pi 4, 4Gb model. It currently has a 16Gb SD card, but I will be swapping that for a larger one.\nThe Pi next to the USB Hub\nOn top of that, is a UPSPack V3. This is a cheap but feature rich UPS board for Raspberry Pi\u0026rsquo;s. It can do 5V, 3A output, report data to the Pi via serial (such as charge status) and shutdown the Pi gracefully before the battery runs out.\nIt handles charging via USB-C and has a pair of external (unused in my design) USB ports for powering other devices. I also soldered wires for an external switch that is mounted in the back panel of the cyberdeck.\nStacked neatly on top of each other\nNext to the Pi is an \u0026lsquo;internal\u0026rsquo; USB hub, its designed for use in PCs for running things like RGB and Fan Controllers, but it was perfect for my application. It is a 4 port hub with standard USB headers like you\u0026rsquo;d find in any PC.\nUpdate: I tested the battery life by running Chrome with a YouTube video playing and logging the uptime every 2s to a file. The result was 3h 40m of runtime.\nNestled between the Pi and the battery\nI attached a USB plug to its cable, which is plugged into the bottom USB2 port on the Pi, this whole mess is covered by a plate. I think I might change this design by soldering wires to the underside of the Pi and then just blanking the usb port.\nNot the most elegant, but it works\nConnected to this hub is they keyboard, display and SDR. I made custom mini and micro USB to header cables to connect the various peripherals.\nThe SDR is a cheap RTL-SDR board I got from amazon, it has two RF inputs and is in a neat metal case to keep it isolated from other devices. It connects via mini USB to the internal hub\nI did have a plate for this side, but it made using the RF connectors a pain\nThe keyboard is the same as used in previous attempts. It has \u0026lsquo;RGB\u0026rsquo; lighting (not customisable sadly\u0026hellip; I did have one that was but I managed to fry it üò¢).\nThe RGB is actually kind of a pain, as it draws a lot of power and causes weirdness when the cyberdeck is booted without being plugged in to mains. I am likely to disable it (read: cut the power traces for it üòà) in future.\nIt is a fairly basic \u0026lsquo;cheap\u0026rsquo; mechanical keyboard, but its actually not too bad to type on and its fits the aesthetic I was going for. It connects via mini-USB to the internal hub.\nThe keyboard in all its glory, and the official RPi mouse!\nFinally, the display is a 7\u0026quot; IPS LCD. It has a resolution of 1024x600 and includes capacitive touch. It connects to the Pi via HDMI and the power and touchscreen via a micro USB cable. The cable is also spliced in to the UPSs\u0026rsquo; 5v output as the screen draws a lot of current.\nThe display mounted on the cyberdeck\nThe display is connected via a \u0026lsquo;custom HDMI cable kit\u0026rsquo; from The Pi Hut. It allows you to mix and match connectors for HDMI and uses a flex flat cable to go between them, quite useful for things like this.\nThere is a panel on the back of the unit to cover the connections, but leaving open the power input (on the UPS Board) and the 3.5mm audio jack\nYou can still access the ports you need to\nThat\u0026rsquo;s pretty much it for the hardware. It\u0026rsquo;s a standard Raspberry Pi 4. There are 2x USB3 ports accessable, 1x USB2 and 1x Gigabit Ethernet.\nBill Of Materials Below is a pretty much complete list of the parts used and where I got them from. Prices are as at the time I purchased. You can likely find things cheaper on sites like Aliexpress, or you can even swap things out for other hardware.\nDevice Description Cost/Vendor Raspberry Pi 4 4Gb Model ¬£54 Pimoroni UPSPack V3 UPS \u0026amp; Battery ¬£25.99 Amazon USB Hub Internal USB Hub ¬£7.59 Amazon AK33 Mechanical Keyboard ¬£31.99 Amazon SDR KKMoon RTL-SDR ¬£32.99 Amazon Display 7\u0026quot; HDMI IPS Touchscreen ¬£28.05 Aliexpress USB Cable 2x 50cm Mini-USB Cables ¬£2.99 ea Amazon USB Cable 1x Right angle micro-USB Cables ¬£3.99 Amazon HDMI Connector Up angle micro HDMI Connector ¬£6 The Pi Hut HDMI Connector Standard HDMI Connector ¬£6 The Pi Hut HDMI Cable 50cm Flex Cable ¬£3 The Pi Hut Dupont Connectors 1550 pcs kit + Crimp Tool ¬£20.99 Amazon Nuts \u0026amp; Bolts 440 pcs kit ¬£15.99 Amazon Software Right now, the deck is simply running Raspbian, with a few little tweaks to make things like the UPS and Display work correctly.\nI might try out other distributions in the future, such as Kali Linux, but for now Raspbian is fine!\nFor a laugh, I installed steam link and had a go at playing Cyberpunk2077 on my cyberdeck. It worked surprisingly well, but I think I\u0026rsquo;d rather my 32\u0026quot; 1440p gaming monitor over a 7\u0026quot; 600p display running at 30Hz\nClick the thumbnail to see the video\nDisplay\nThe display \u0026lsquo;works\u0026rsquo; out of the box as its a simple HDMI display, and the touch drivers are included in Raspbian, so the only thing I needed to do was set some config to have it run at its native resolution. I used the guide from Adafruit here, but the TL;DR is:\nadd the below lines to /boot/config.txt and reboot.\nhdmi_group=2 hdmi_mode=1 hdmi_mode=87 hdmi_cvt=1024 600 60 3 0 0 0 UPS\nThe UPS also \u0026lsquo;works\u0026rsquo; but requires some config changes if you want to be able to see the data over serial, or have the Pi shutdown automatically. They are details in the documentation here.\nYou will need to download the scripts they provide if you want a nice way to view the UPS details, but if like me you just need to get the data flowing (I plan to build my own software to show battery status) then add the below to your /boot/config.txt and reboot.\nenable_uart=1 dtoverlay=disable-bt Once you\u0026rsquo;ve done that, you\u0026rsquo;ll be able to see the data on /dev/ttyAMA0 at 9600baud.\nInspiration, and why would I want to do this? Like a lot of hardware projects, its better to ask\u0026hellip; why not?\nThere are plenty of practical reasons you might want to build your own cyberdeck\u0026hellip; maybe you want something portable for \u0026lsquo;hacking in the field\u0026rsquo;, something that contains the exact hardware you need for that\u0026hellip; such as a built in SDR like my deck has.\nBut largely, at least for me, I built one because I wanted to. The first deck I remember seeing that made me think about building my own was the \u0026lsquo;Off-Grid cyberdeck\u0026rsquo; by back7. I saw it browsing hackday a few years ago and loved the idea of a portable pi, with custom hardware (e.g the GPIO ports and network switch in back7\u0026rsquo;s deck.\nThere was also decks like \u0026lsquo;The Virtuscope\u0026rsquo; and this awesome NUC based deck. Sites like they cyberdeck cafe and the cyberdeck subreddit are full of inspiring builds.\nMore generally, the whole \u0026lsquo;cyberpunk\u0026rsquo; / \u0026lsquo;retrowave\u0026rsquo; / \u0026lsquo;retro-future\u0026rsquo; aesthetic is something that appeales to me.\nSo will I used this deck for anything? Maybe, maybe not. Did I enjoy building it? Certainly, and that\u0026rsquo;s really all that matters.\nConclusion This current iteration of my cyberdeck is one I am finally \u0026lsquo;happy\u0026rsquo; with. It\u0026rsquo;s definitely not perfect, and no doubt I will change and improve the design in the future. But I have enjoyed building it, and hopefully given you some inspiration to build one yourself.\nIf you want to build your own, the STL files are available on thingiverse here, and you can use the above table for the hardware you\u0026rsquo;ll need.\nIf you can think of ways to improve my design, or this has inspired you to create your own I\u0026rsquo;d love to hear about them, you can send me a tweet @mickwheelz_!\n","date":"2021-01-17T17:30:00Z","site":"https://sophieis.lgbt/","tags":["cyberpunk","cyberdeck","raspberry pi","sbc","hacking","hardware"],"title":"Yet another Raspberry Pi Cyberdeck","uri":"https://sophieis.lgbt/posts/2021-01-16-yet-another-raspberry-pi-cyberdeck/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["salesforce","microservices"],"content":" Now that the holidays are over, its time for Part Two! Haven\u0026rsquo;t read part one yet? Check it out and then come back, don\u0026rsquo;t worry, I\u0026rsquo;ll wait for you.\n‚åöÔ∏è\nFinished? Great, let\u0026rsquo;s go!\nHow does this work on Salesforce? As we discussed in part one, we can take advantage of the Salesforce enterprise messaging platform to build \u0026lsquo;microservices\u0026rsquo; in Salesforce.\nBefore we go any further, these microservices are a little different from traditional ones. As we know, Salesforce provides a platform as a Service. This includes everything we need, including the database, the runtime, the language, etc. As we know, we can only use the tools provided by the platform. We can\u0026rsquo;t just deploy some random java to our salesforce org (yet\u0026hellip; üòâ) so we must write our on-platform services in Apex* and we use the database we are given*\n*(yes there are other languages/databases (e.g JS in Aura/LWC and External Objects\u0026hellip; but that\u0026rsquo;s out of the scope of this post!)\nSo in reality, our services are discrete \u0026lsquo;chunks\u0026rsquo; of Apex that don\u0026rsquo;t have dependancies on other code, or potentially even objects in Salesforce (aside from the Platform Event definition they use).\nWe still get most of the same advantages as traditional microservices. We can however, have microservices in our Application that are outside of salesforce, and these can behave as traditional microservices, with their own language, database, runtime, etc. We will cover these too!\nSo let\u0026rsquo;s take a look at how we do this\u0026hellip;\nOn Platform Let\u0026rsquo;s think about the example from part one. We have a simple billing system that uses Opportunities and Opportunity Line Items. When an Opportunity is closed/won, we want a PDF invoice (with the line items listed on it) generated and attached to the Opportunity.\nUsing the \u0026lsquo;old\u0026rsquo; way, you might have a trigger on the opportunity that uses VisualForce to generate the PDF and attach it to the Opportunity. This runs on synchronously on save and you may eventually run into limit issues with this approach.\nSo how do we do it using microservices? Well let\u0026rsquo;s take a look at the below diagram\nIf you want to see the example code for this approach, you can check out the repo here and it is referenced below.\nYou can see here we have three \u0026lsquo;services\u0026rsquo;;\nThe Apex trigger OpportunityChangeEventTrigger, is on the Opportunity Change Data (CDC) event, so it isn\u0026rsquo;t run synchronously. It simply it calls the OpportunityChangeEventService class to fires the Invoice Request Platform Event (PE) that contains the information needed to generate the Invoice. This approach is taken to decouple the next service from the Opportunity. The Invoice generation service. This listens for the Invoice Request PE in the GenerateInvoicePDFTrigger, then calls the InvoicePDFService and it uses VisualForce (InvoicePDF / InvoicePDFController) to generate a PDF invoice from the information contained in the event. It knows nothing about the original opportunity (this is important!) When it is finished it simply fires a \u0026lsquo;Invoice Response\u0026rsquo; PE. It ONLY generates PDFs, nothing else. Finally, we have InvoicePDFTrigger that listens for the Invoice Response PE and then calls the InvoicePDFService so that it can insert an attachment record. It doesn\u0026rsquo;t know or care where the PDF actually came from. None of these services have any hard dependencies on each other. They do their small individual jobs and that is it. They also all run asynchronously so the user doesn\u0026rsquo;t need to sit and wait for them to complete for their record to be saved.\nWant to see how this looks under the hood? Well you can check out the code here\nSo what happens when our little VisualForce PDF generator service stops scaling or is otherwise unfit for purpose? Well, we simply replace it with something\u0026hellip;\nOff Platform We\u0026rsquo;ve decided we are going to use a small service running on Heroku to generate our PDFs now, so we\u0026rsquo;ve written something in NodeJS and deployed it. Let\u0026rsquo;s take a look at how we switch to using this now.\nIf you want to take a look at the code for the Heroku service, you can see it here, It is referenced below.\nYou can see we again have three services, and the first and third have not changed. The code is identical. We have ONLY replaced the middle service.\nThe NodeJS is very simple, in index.js the begin() function it logs in to Salesforce (to access the event bus) and then begins listening for Invoice Request PEs. If it receives one, it calls processGenerateInvoicePDFEvent() which uses PDFKit to generate the invoice PDF, this is handled in generateInvoice.js\nWhen it is finished generating the PDF, fireInvoicePDFEvent is called to fire the Invoice Response PE for to be picked up by our attachment service inside salesforce.\nTo handle the Salesforce requests, we are using the excellent JSForce library.\nNow that we have our little PDF service running, I bet you are wondering how we switch to using it.\nWe disable GenerateInvoicePDFTrigger \u0026hellip; that\u0026rsquo;s it. Seriously.\nIf we want to switch back, all we need to do is shut down our Heroku service and switch the trigger back on. Simples!\nOf course, in the real world we would likely remove the trigger from production once we had finished migrating to the new service, but you can see how simple it is with this approach.\nNow that we\u0026rsquo;ve see how we can create microservices on and off platform, and swap them at will we should\u0026hellip;\nWrap Up The event driven paradigm is a very flexible one and allows things to change without the usual level of friction. It can speed up development, and allow teams to work in parallel. It can even speed up the end user experience, as everything is done async. It is an excellent option for large and complex Applications, but it is not a silver bullet.\nIt does introduce more \u0026lsquo;moving parts\u0026rsquo;, for smaller, simpler applications this may not be worth it. It is also worth considering the limits of platform events, for very large volumes you may need to move to a different event bus, such as Apache Kafka. Salesforce cannot natively talk to Kafka, but you can use middleware like MuleSoft or you can build your own bespoke services to do so (a topic for a future post perhaps\u0026hellip; ü§î)\nYou should always take time to consider what is the right approach for what you are building, both now and in the future. However I hope this post has informed and inspired you to think about how you could use this architecture in Salesforce!\nIf you\u0026rsquo;ve got any questions or comments, please send me a tweet @mickwheelz_\n","date":"2020-12-27T13:00:00Z","site":"https://sophieis.lgbt/","tags":["salesforce","microservices"],"title":"Microservices inside Salesforce With Platform Events and Change Data Capture, Part Two","uri":"https://sophieis.lgbt/posts/2020-12-27-microservices-inside-salesforce-with-platform-events-and-change-data-capture-part-two/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["salesforce","microservices"],"content":" Normally, when I do a talk at Dreamforce, or another conference, I write a follow up blog post covering the same content. But the end of 2019 was pretty busy with Dreamforce, Monkey Run Morocco, French Touch Dreamin and Christmas/Holidays. I figured I\u0026rsquo;d get it written up in early 2020\u0026hellip;\nThen 2020 happened\u0026hellip; and turned in to a complete dumpster fire. With everything going on, I was finding it difficult to find the time and motivation to write anything. With the year almost over, and my blog revamped I knew I wanted to get it written.\nEnough boring excuses. Here we go.\nThis is part one of the follow up post to my talk \u0026ldquo;Microservices inside Salesforce With Platform Events and Change Data Capture\u0026rdquo;. If you did catch my talk at Dreamforce 2019, or London\u0026rsquo;s Calling 2020, I hope you enjoyed it. If not (or even if you did!), read on as I will cover the same topics here.\nIn part one we will cover the concepts, and in part two, the implementation. The first thing we need to understand is\u0026hellip;\nWhat are microservices? The key to microservices is kind of in the name; small (micro) services. These services generally cover a specific functional area, or function and perform only that function. (e.g generating documents, or handling payments).\nIdeally, these services are independently deployable, maintainable and testable. In larger applications or organisations these services are often developed and maintained by different teams, even using different languages or tech stacks. They are loosely coupled to other services and shouldn\u0026rsquo;t have any \u0026lsquo;hard dependencies\u0026rsquo; on them.\nWhen grouped together, all of these services, and their supporting infrastructure make up a larger application (e.g a Billing System).\nA good analogy is the robots in a car factory. You have robots to weld the cars, robots to paint them and so on. The painting robot is independent of the welding one. It does not know how to weld, or care how the car was welded. All it does is paint the car and send it on to the next station (micro service) in the factory (application)\nOne of the key benefits of this is it means that when it comes time to upgrade the welding robot, the painting one does not need to be changed. Likewise if the painting robot needs to be changed, the welding robot doesn\u0026rsquo;t care.\nAs you\u0026rsquo;ve probably experienced, changing chunks of a normal \u0026lsquo;monolithic\u0026rsquo; type application can be painful, as it\u0026rsquo;s often tightly connected to other parts of the application with no easy way to change just the one part you need to.\nWith a microservice approach, often these issues are either removed entirely, or heavily mitigated.\nThis is great and all, but these micro services need a way to communicate with each other, this needs to be in a \u0026lsquo;common language\u0026rsquo; they can all understand, so this brings us to\u0026hellip;\nWhat is an event-driven architecture? So as alluded to above, this approach hinges on these services having a common way to talk to each other. If I\u0026rsquo;ve got a service written in Apex on Salesforce, it has to know how to talk to a service written in NodeJS on Heroku, or something written in Java running on-prem.\nThis is where an event-driven architecture comes into play. It means that all of these services share a common eventbus on to which they publish (or push) to and subscribed to (or consume from), normally these events are segregated into topics or channels. I am going to use the terms publish, subscribe and topic to describe this from here on out.\nThe event bus sits in the middle of all of these microservices, services produce and subscribe to it to move data between them and perform their functions. The event bus also often manages things like queueing, replay of events, access to topics and security. Some common event buses are Apache Kafka, MQTT and CometD. Salesforce of course also has its own event bus, the Enterprise Messaging Platform (often just called Platform Events, which uses CometD)\nTo better understand this concept, let\u0026rsquo;s think for a second about twitter, it is like an event bus. If I see #Salesforce trending on twitter, I might click on that hashtag. This would mean I am \u0026lsquo;subscribing\u0026rsquo; to the Salesforce \u0026rsquo;topic\u0026rsquo;. If I then tweet \u0026ldquo;#Salesforce is awesome\u0026rdquo; I am then \u0026lsquo;publishing\u0026rsquo; to Salesforce \u0026rsquo;topic\u0026rsquo;, and anyone else following #Salesforce (aka subscribing to that topic) will see that message. Your microservices work the same way.\nEach service will publish and subscribe to topics it \u0026lsquo;cares\u0026rsquo; about in order to function. It doesn\u0026rsquo;t really have any knowledge of the other services, it just grabs the information it needs to do its job, and publishes its results for other services to do the same. This of course allows for services to be swapped/changed/enhanced without causing impact to other services within the application.\nAnother key feature of an event driven architecture is the ability for multiple subscribers to subscribe to the same topic. Often we only want one service producing to a topic, but there are exceptions to this rule.\nFor example, if I am building a billing system, perhaps I need to perform some tasks when an Opportunity is closed/won. I might need to generate a PDF invoice to send to the customer or I might need to generate a packing slip to send to a warehouse. If all of these subscribe to the \u0026lsquo;Opportunity\u0026rsquo; topic, then all of them can perform their task independently when they receive a closed/won opportunity message on that topic. Likewise, if I have one source of truth for Opportunity data (Salesforce) then I don\u0026rsquo;t want other systems publishing data to the Opportunity topic.\nIf in the future I also need to activate the customer\u0026rsquo;s new service in another system, the new system can simply listen to this topic! We don\u0026rsquo;t need to make any changes to the existing systems, we can just \u0026lsquo;bolt on\u0026rsquo; this new system.\nAll of this sounds exciting right? So\u0026hellip;\nHow does this relate to Salesforce? Salesforce has a number of tools to help us out here, under the banner of \u0026lsquo;The Salesforce enterprise messaging platform\u0026rsquo;. This is often just called \u0026lsquo;Platform Events\u0026rsquo;, however Platform Events are just one of the tools available to us.\nThere are two we are going to cover in detail here, Platform Events and Change Data Capture.\nSo let\u0026rsquo;s start with\u0026hellip;\nPlatform Events Platform Events in this context is the term salesforce gives to custom topics. e.g topics we are developers are able to define and use for whatever we like.\nWe can define a platform event in much the same way as a Custom Object. They have a name like \u0026ldquo;My_Cool_Event__e\u0026rdquo; and have various field types that can be added to them (text, numbers, checkboxes, etc) which will contain the data for subscribers to use, or for publishers to populate.\nOnce we have defined our platform event \u0026rsquo;topic\u0026rsquo;, we can then publish events to it. This can be done from within Apex code, from processes or flow, or via Salesforce APIs from external services.\nWe can also subscribe to events from Apex triggers, processes, flows, lightning and visualforce components, or in external services via CometD.\nPlatform events are the most flexible kind of event, as they can be defined to contain any information we want, and be published or subscribed through a number of different methods.\nThere however is another very useful kind of event, these are\u0026hellip;\nChange Data Capture Change data capture (CDC) is a feature of Salesforce that publishes \u0026lsquo;change events\u0026rsquo;, These events represent changes to Salesforce records. Things that are classified as changes, and thus are published include creation of a record, updating a record, and deleting or undeleting a record. Once enabled for an object, these events are automatically published by Salesforce.\nChange data capture is similar in a lot of ways to Platform Events and, in fact, uses the same underlying bus. The main difference is that publication of these events is done automatically by salesforce, and the layout of data within them (their schema) is unable to be changed by us. We can, however, subscribe to these events in the exact same way as a Platform Event.\nWhy is CDC important? Well it means that we can subscribe to any change in data across Salesforce, so in our billing example above, we don\u0026rsquo;t need to define our own \u0026lsquo;Opportunity\u0026rsquo; event, we can simply enable CDC and subscribe to the events we need.\nNow that we know about CDC, we need to\u0026hellip;\nPut it all together We know that the \u0026lsquo;Salesforce Enterprise Messaging Platform\u0026rsquo; is our event bus. It is a part of Salesforce, and our publishers and subscribers (aka our micro services) need to be able to access it. For services on platform, it\u0026rsquo;s easy.\nThere is nothing special that needs to happen (aside from creating Platform Events or enabling CDC), you just need to build them. It\u0026rsquo;s slightly harder with Services outside of Salesforce. They need users accounts, and the appropriate level of access and your micro services needs to understand how to publish or subscribe to events (more on this in part two\u0026hellip;)\nWe also know that our topics are Platform Events (if defined by us) or Change Data Capture (defined by Salesforce). We know that we can subscribe to both CDC and Platform Events in a variety of ways both on and off platform. We also know that we can publish Platform Events in a number of ways both on and off platform. Finally, we know that CDC events are published for us by Salesforce (once enabled).\nConclusion and Further Reading In part one, we covered the main concepts, microservices and event driven architecture. How they work together and how they apply to Salesforce with Platform Events and Change Data Capture.\nIn part two we will cover how to build an application with these concepts, including how to swap out a service within that application to an off-platform version!\nI hope you\u0026rsquo;ve found this informative, and if you\u0026rsquo;ve got any questions or comments, please send me a tweet @mickwheelz_. If you want to learn more in the meantime, check out the links below;\nSalesforce Blog - Which Streaming Event Do I Use?\nTrailhead - Platform Event Basics\n","date":"2020-12-12T15:00:00Z","site":"https://sophieis.lgbt/","tags":["salesforce","microservices"],"title":"Microservices inside Salesforce With Platform Events and Change Data Capture, Part One.","uri":"https://sophieis.lgbt/posts/2020-12-12-microservices-on-salesforce/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["electronics","motorcycle"],"content":" One of the small handful of motorcycles I own is a 2015 Honda CRF250L. I bought it after doing the Monkey Run Morocco in 2019 (maybe I should write about that one day\u0026hellip;) and realising this whole off road / adventure motorcycling thing is a lot of fun.\nThe CRF250L is an excellent beginners adventure bike. It\u0026rsquo;s lightweight, easy to ride and decent off road. It\u0026rsquo;s not an Africa Twin by any stretch, but for someone like me who is starting out, it\u0026rsquo;s great.\nThat said, there is room for improvement. The bike had a few choice mods when I bought it. Things like a smaller front sprocket (for a bit more low down torque), aftermarket air filter, bar risers, heated grips, hand guards, foldable mirrors and a rear rack.\nOne of the things I disliked about the bike was how basic its dash was. It has no tach and no temp gauge. You get speed, fuel, time and some lights\u0026hellip; that\u0026rsquo;s it.\nIt has an over-temp light, and obviously you don\u0026rsquo;t need a tachometer, but it is nice to have a better idea of what the bike is doing.\nI wondered if, being a somewhat modern bike, there would be some sort of diagnostic port that I could connect to to get this data. As it turns out, there is!\n\u0026ldquo;Modern\u0026rdquo; Honda motorcycles have a 4 pin connector called a HDS port. This is similar in function to the OBD port in a car. In fact that was one of the first approaches I looked in to, after finding HDS to OBD adapter cables online.\nAfter further research (huge shout-out to the PGM-FI forums) found that Honda does use a standard protocol (KWP2000), but most cheap ELM327 OBD adaptors (including the one I had) are incompatible with it, as it has a non-standard initialisation sequence. I did try it anyway, after making a cable (aka jamming some wires into the HDS port and clipping them to the ELM327 device) I was able to confirm it didn\u0026rsquo;t work.\nSo I kept looking and stumbled across two things that made me realise this was possible. The first was the CTX-OBD project that had a similar goal/idea to what I was hoping to do. The second was the KWP2000 library for arduino that Aster94 had on GitHub.\nI didn\u0026rsquo;t end up using the KWP2000 library (as it\u0026rsquo;s only been implemented for Suzuki) but I did use the hardware (namely a L9637D bus driver)\nI was able to finally prove the theory with some very ropey code, an Arduino Nano and the L9637D.\nOnce the excitement of seeing data from my bike\u0026rsquo;s ECU being displayed on my laptop, I had to think about how I would build the actual device.\nFor the display, I decided to use an cheap ILI9341 SPI display, as they are easy to work with and I had a few laying about. For the microcontroller I went with an ESP32. I could\u0026rsquo;ve used the Arduino Nano, but the ESP gives me a much faster CPU, more memory, more peripherals and the option to use things like WiFi and Bluetooth in the future. They are also incredibly cheap and I had a few of them kicking around.\nI put together a prototype using the ESP32, a display and the L9637D chip.\nAfter much tweaking it all worked and I knew the design was viable, so I designed a PCB in Eagle CAD. I sent it over to PCBWay for fab (my first time using them) and a week or so later these turned up.\nI was very happy with the PCBs. They did have a small mistake, which was entirely my fault and only required cutting a trace. After fixing that and soldering everything on, I was able to flash the firmware I\u0026rsquo;d written and it was ready to go. I added a few more features like an external temperature sensor (using a DHT22) and a GPS module for speed/heading/etc.\nI needed a case, so designed something basic in Fusion360 and 3D printed it. I decided to go with a generic GoPro style mount on the bottom, which I paired with a handlebar mount I had to mount it to the bike.\nI mounted it to the bike, and lo and behold, it worked! I took the bike for a ride and discovered a few bugs in the firmware (like the speed being reported in KPH not MPH) but it actually worked!\nI have done a much more technical write-up on the project\u0026rsquo;s GitHub repo, which includes a wiki.\nSo whats next? Well I\u0026rsquo;ve designed a version 2 of the PCB, which has simpler power delivery, and uses a display directly mounted to it. I will cover this new version in a future blog! I also need to do some more work on the firmware, and the documentation, which will come in time.\nThis should work on other Honda bikes, so if you\u0026rsquo;ve got a Honda made in the last 10 years or so, and give it a try please do let me know how you go!\n","date":"2020-11-21T15:00:00Z","site":"https://sophieis.lgbt/","tags":["electronics","motorcycle"],"title":"Building a information display for my CRF250L","uri":"https://sophieis.lgbt/posts/2020-11-21-building-a-information-display-for-my-crf250l/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":["retropie","electronics","i2c","nintendo"],"content":"I recently found myself in Poundland seeing what a humble pound coin could get me, aside from the usual cables, chargers and similar accessories I buy‚Ä¶ seriously, they work fine and are only ¬£1/¬£2, not to mention their chargers are far better than cheap ones you‚Äôd find on ebay! Check out this video from bigclivedotcom on the subject.\nAs I was browsing, I happened upon the ¬£5(!) electronics/games section. There were a few XBOX360 games and such, but what caught my eye was this;\nI forgot to take a photo at the shopIt is a Gioteck ‚ÄòTurbo Controller‚Äô for the Nintendo Classic Mini. It looks basically like a NES controller with turbo buttons. Considering my RetroPie setup at home, but having no idea of the protocol/connector it used, I decided it was worth the sacrifice of ¬£5 to find out if I could make it work. You can also get these controllers from the likes of argos/ebay (for ¬£5.99, the horror!).\nI got it home, opened it up and saw the Nintendo ‚Äònunchuck‚Äô style plug on the (surprisingly long) cable. This was a good start and I figured that it probably uses the same protocol as the Nunchuck or the Wii Classic Controllers and similar that use the same plug. Both of these use the I2C protocol and there are various libraries out there to allow them to be use with Arduino‚Äôs and compatible micro-controllers.\nI was hoping there would be something similar for the Raspberry Pi, given it has an I2C bus built in, but unfortunately the only information I could find was on drivers for the Wii controller with a Nunchuck or Classic Controller connected to it, connected to the Raspberry Pi over bluetooth, which was no use to me as I don‚Äôt own a Wii controller.\nSo I decided to write my own ‚Äòdriver‚Äô for it (more of a daemon actually!) and here is how I did it;\nFirst thing I had to do was crack it open to see if I could find the pinout. Mercifully it was printed right on the board, along with several test points I plan to investigate later. I2C devices generally use four wires VIN (Power, 3.3v) GND (Ground), SDA (Data) and SCL/CLK (Clock).\nIn this case, VIN is red, GND is black, SDA is green and CLK is white.\nController PCB with connections labeledGiven that this experiment was so cheap, I simply cut off the nunchuck style plug to expose the wires and I then attached my own pin sockets/plug for easy connection to a Raspberry Pi or other devices.\nController with new Raspberry Pi compatible plugAdding the plug made it very easy to connect and disconnect it from the various raspberry Pi‚Äôs I used for testing, namely a Raspberry Pi 3 I use to run RetroPie in my lounge room, and a Raspberry Pi 0W that I used for headless testing/development.\nConnected to the Raspberry PiIf you didn‚Äôt want cut it up, you can get you could grab a ‚ÄòNunchucky‚Äô from adafruit and solder wires and an appropriate plug to that, or scavenge sockets from a broken system.\nOnce I had the new plug on it, I connected it to an Arduino nano to do some testing. I initially tried the WiiClassicController library to see if it used the same protocol as the Nunchuck/Classic Controller and luckily for me, it did. So now I had to work out a way to get that data into a useable form on the Raspberry Pi using its I2C bus.\nIdeally you would write a kernel module in C for this, but given my very limited knowledge of C and desire to get it running quickly I had to pick something else. I am most comfortable with Java so my my first attempt was to write a simple app that used the PI4J and Robot libraries to take the data from the I2C bus and turn it in to keyboard commands. This was very quick and easy to write, but unfortunately was a failure as Robot on linux requires X11 to be running for it to work, and RetroPie does not use X11.\nI looked around, and a good way to achieve keyboard emulation at a lower level was with the ioctl call, and there happens to be an wrapper for it in NodeJS. I am not brilliant with JS but I have written node app‚Äôs before and figured it was going to be easier than learning C (which I do want to do at some stage!)\nMy first attempt was using the virtual-input library, but nothing I did would make it work with the Raspberry Pi. I could get it work fine on an ubuntu VM to send keystrokes, but never on the Pi.I saw that it was used in another project, node-virtual-gamepad which is a really cool project. So I tried it and it and worked fine on the Pi.\nI then had a look through the source to see if I could extract its virtual keyboard code for use in my own project and after much wrangling, I got it to work! I used evtest to detect the virtual keyboard codes as they were sent by the virtual keyboard code.\nevtest runningThe next thing to do was integrate the keyboard code with the I2C library to come up with some sort of daemon that would interpret the commands sent from the controller over I2C into keypresses on the virtual keyboard, thus controlling the game.\nThere was also code for emulating joysticks/gamepads which I do plan to build in to the daemon, so that you can choose to emulate a keyboard or gamepad depending on your needs. But the first order of business was to get it working as a virtual keyboard.\nOnce I had both portions working, both I2C reading and virtual keyboard, i was able to combine them to build the daemon that will run in the background and interpret the data from the controller in to keyboard presses to control the Raspberry Pi.\nTesting it out with a bit of MarioThe code and is available on my github here, along with instructions on how to setup and use it. If you want more detail on how I built it, read on.\nOnce I had both the virtual keyboard and I2C code working combining them was relatively straightforward, but there were a few gotchas.\nAs I learned from the Arduino library, the gamepad sends data in ‚Äòpackets‚Äô of 6 bytes When there is no buttons pressed, the result always begins with a 0x0 (0) with the packet looking like this (decimal); [ 0, 0, 128, 128, 255, 255 ] The gamepad sends a ‚Äòheartbeat‚Äô packet of 6x 0xFF (255) byte values every ~8 seconds and a randomly times packet that begins with 0x1 (1), these look like this (decimal); [ 1, 0, 164, 32, 1, 1 ] [ 255, 255, 255, 255, 255, 255 ] In the linux event subsystem when a key is pressed a 1 is sent and it will remain pressed until a 0 is sent for the same key, you can send multiple 1‚Äôs and 0‚Äôs at once All 8 buttons are handed by the last two bytes in the array (5 and 6) and some buttons when pressed together send a new code if they are on the same byte. I had to test and map these out. I needed to ensure that 2 buttons can be pressed at a time in order for the controller to be useful Below is a table of the keys to their ‚Äòbytes‚Äô that I am using to detect keypresses; Button Position Hex Dec D-pad Up Byte 5 0xFE 254 D-pad Down Byte 4 0xBF 191 D-pad Left Byte 5 0xF3 253 D-pad Right Byte 4 0x7F 127 Start Byte 4 0xEF 239 Select Byte 4 0xFB 251 A Byte 5 0xEF 239 B Byte 5 0xBF 191\nGiven that some buttons share the same byte (such as A\u0026amp;B) they give different results if pressed at the same time. Below is a table of the ‚ÄòCombination‚Äô bytes and positions;\nCombination Position Hex Dec A \u0026amp; D-pad Up Byte 5 0xEE 238 B \u0026amp; D-pad Up Byte 5 0xBE 190 Select \u0026amp; Start Byte 4 0xEB 235 A \u0026amp; D-pad Left Byte 5 0xED 237 B \u0026amp; D-pad Left Byte 5 0xBD 189 D-pad Up \u0026amp; D-pad Left Byte 5 0xFC 252 D-pad Down \u0026amp; D-pad Right Byte 4 0x3F 63 D-pad Down \u0026amp; Start Byte 4 0xBB 187 D-pad Down \u0026amp; Select Byte 4 0xAF 175 D-pad Right \u0026amp; Select Byte 4 0x6F 111 D-pad Right \u0026amp; Start Byte 4 0x7B 123 A \u0026amp; B Byte 5 0xAF 175\nOnce I had this information, the code itself is fairly simple.\nIt polls the controller every 10ms (this can be changed) for the 6 byte array. From that I build JSON object containing each button and its state (0 or 1). I then check this against the last iteration to see if its changed to detect a change in state of a button, if its changed I then set the key high or low using the virtual keyboard library, at the end of the iteration i pass the current button states in to the ‚Äòold‚Äô iteration variable and start again. Only if the key has changed from one iteration to the next do I send a key event to change its state in the events subsystem.\nThe daemon is designed to be run in the background upon boot of the system to register events from the controller and pass them to the virtual keyboard. I also noted that the controller can be connected and disconnected while the daemon is running with no ill effects.\nLet me know if you found this useful or interesting, or if you have any suggestions on improving it!\n","date":"2018-02-23T00:00:00Z","site":"https://sophieis.lgbt/","tags":["retropie","electronics","i2c","nintendo"],"title":"A RetroPie (or similar) controller for ¬£5?!","uri":"https://sophieis.lgbt/posts/2018-02-23-a-retropie--or-similar--controller-for--5/"},{"author":{"about":"just another transfem stereotype.... computers, electronics, general nerdery","email":"me@sophi.ee","image":"img/me-gh.jpg","name":"Sophie üå∏"},"categories":null,"content":"A while ago, I came across someone using emoji as a Wi-Fi network name (SSID), I tried to do the same on my wifi router (I wanted the delightful smiling poo emoji üí©) but my router, sadly wouldn‚Äôt let me.\nI saw it again the other day, and I thought I‚Äôd have another try, after all this was years ago and I have a much newer router, and newer version of DD-WRT running on it.\nBut, I was rudely told that what I was trying to do was illegal.\nNot to be deterred, I thought I‚Äôd try changing it via SSH‚Ä¶ but that was not to be either.\nInserting the emoji returned ‚Äúp)‚Äù which was not accepted, I did also try the unicode char for it ‚ÄúU+1F4A9‚Äù but that didn‚Äôt work either.\nTurning to google, I wondered if anyone had done this successfully before, but all I could find was this article, This was done on the same model of wireless router as I own, but using the stock firmware.\nBut it did give me a good idea‚Ä¶ So taking the same approach as in the article, but skipping straight to the server-side method, I used chrome dev tools to inspect the request;\nSo that is all well and good, but I need to replicate the request with new parameters, so turning to postman\nFingers crossed, I hit send on the request‚Ä¶ and low and behold!\nSuccess!\nSo far I‚Äôve not had any issues with modern-ish devices finding/connecting to it, however I did leave the 2.4ghz radio of my wireless router alone, so that older devices can use it if need be.\n","date":"2017-07-26T00:00:00Z","site":"https://sophieis.lgbt/","tags":null,"title":"‚Ä¶and now for no reason: Emoji‚Äôs in your Wi-Fi name!","uri":"https://sophieis.lgbt/posts/2017-07-26--and-now-for-no-reason--emoji-s-in-your-wi-fi-name/"}]